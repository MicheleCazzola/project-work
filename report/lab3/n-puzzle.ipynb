{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from heapq import heappush, heappop\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 4\n",
    "RANDOMIZE_STEPS = 10_000\n",
    "STEP_SIZE = 1000\n",
    "TEMPERATURE = 10\n",
    "MIN_PUZZLE_DIM = 2\n",
    "MAX_PUZZLE_DIM = 7\n",
    "TRIALS_BASE = 10\n",
    "OUTFILE = \"out.json\"\n",
    "\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State\n",
    "Class to make a numpy array hashable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, content: np.ndarray):\n",
    "        self.content: np.ndarray = content\n",
    "        self.hash: int = hash(content.tobytes())\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return self.hash\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.hash == other.hash\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.hash < other.hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    puzzle_dim = state.shape[0]\n",
    "    x, y = [int(i[0]) for i in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < puzzle_dim - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < puzzle_dim - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def counter(fn):\n",
    "\n",
    "    @functools.wraps(fn)\n",
    "    def helper(*args, **kargs):\n",
    "        helper.calls += 1\n",
    "        return fn(*args, **kargs)\n",
    "\n",
    "    helper.calls = 0\n",
    "    return helper\n",
    "\n",
    "@counter\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance computation\n",
    "Sum of Manhattan distances, eventually exponentiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(state_content: np.ndarray, n: int) -> tuple[int, int]:\n",
    "    x, y = np.argwhere(state_content== n)[0]\n",
    "    return x, y\n",
    "\n",
    "def manhattan_distance(state: np.ndarray, goal: np.ndarray, n: int, p: float = 1) -> int:\n",
    "\tx1, y1 = get_pos(state, n)\n",
    "\tx2, y2 = get_pos(goal, n)\n",
    "\treturn (abs(x1 - x2) + abs(y1 - y2)) ** p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics\n",
    "Only *fixed_heuristic* is used in the final solution, as observed in the [experiments](#experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_heuristic(state: np.ndarray, goal: np.ndarray, step: int = None, exp: float = None, p: float = 1) -> int:\n",
    "    puzzle_dim = state.shape[0]\n",
    "    return sum([manhattan_distance(state, goal, n, p=p) for n in range(1, puzzle_dim**2)]) ** exp\n",
    "\n",
    "def step_scheduling_heuristic(state: np.ndarray, goal: np.ndarray, step: int = TEMPERATURE * STEP_SIZE, exp: float = None) -> int:\n",
    "    puzzle_dim = state.shape[0]\n",
    "    return sum([manhattan_distance(state, goal, n) for n in range(1, puzzle_dim**2)]) ** (min(1 + (step // STEP_SIZE) / TEMPERATURE, 2))\n",
    "\n",
    "def arctan_scheduling_heuristic(state: np.ndarray, goal: np.ndarray, step: int = TEMPERATURE * STEP_SIZE, exp: float = None) -> int:\n",
    "\tpuzzle_dim = state.shape[0]\n",
    "\treturn sum([manhattan_distance(state, goal, n) for n in range(1, puzzle_dim**2)]) ** (np.arctan(step / STEP_SIZE) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "Quality is the inverse of path length. If path length is zero (the state is already the goal) is set to the cost.\n",
    "\n",
    "Cost is the number an action is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(solution: list[int]) -> int:\n",
    "    return 1 / len(solution) if solution else cost()\n",
    "\n",
    "def cost() -> int:\n",
    "    return do_action.calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(state: np.ndarray, goal: np.ndarray, heuristic, exp = 1) -> tuple[bool, list['Action']]:\n",
    "    \n",
    "\tpath_len = lambda x: len(x)\t\t# directly defined here to avoid numerical issues if using quality definition\n",
    "\n",
    "\tstate, goal = map(State, [state, goal])\n",
    "\topen_set = []\n",
    "\tclosed_set = set()\n",
    "\tpast_len = {state: 0}\n",
    " \n",
    "\theappush(open_set, (0, state, []))\n",
    "\tclosed_set.add(state)\n",
    "\n",
    "\tsteps = 0\n",
    "\twhile open_set:\n",
    "\t\t\n",
    "\t\t_, current, curr_path = heappop(open_set)\n",
    "\n",
    "\t\t# Only for logging\n",
    "\t\tif steps % 10000 == 0:\n",
    "\t\t\tprint(f\"steps: {steps}, open: {len(open_set)}, closed: {len(closed_set)}, dist: {fixed_heuristic(current.content, goal.content, exp=1, p=1)}, len: {len(curr_path)}\")\n",
    "\n",
    "\t\tif current == goal:\n",
    "\t\t\treturn True, curr_path\n",
    "\n",
    "\t\tfor action in available_actions(current.content):\n",
    "\t\t\tneighbor = State(do_action(current.content, action))\n",
    "\n",
    "\t\t\tif neighbor not in closed_set or past_len[current] + 1 < past_len[neighbor]:\n",
    "\t\t\t\tpast_len[neighbor] = path_len(curr_path) + 1\n",
    "\t\t\t\tcost = past_len[neighbor] + heuristic(neighbor.content, goal.content, step=steps, exp=exp)\n",
    "\t\t\t\theappush(open_set, (cost, neighbor, curr_path + [action]))\n",
    "\t\t\t\tclosed_set.add(neighbor)\n",
    "\n",
    "\t\tsteps += 1\n",
    "    \n",
    "    # It should not arrive here!\n",
    "\treturn False, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(goal: np.ndarray, puzzle_dim: int = PUZZLE_DIM, randomize_steps=RANDOMIZE_STEPS) -> np.ndarray:\n",
    "    state = goal.copy()\n",
    "    np.random.shuffle(state.flatten())\n",
    "    for _ in range(randomize_steps):\n",
    "        state = do_action(state, choice(available_actions(state)))\n",
    "    return state.reshape(puzzle_dim, puzzle_dim)\n",
    "\n",
    "def set_goal(puzzle_dim: int) -> np.ndarray:\n",
    "    goal = np.array([n for n in range(1, puzzle_dim**2)] + [0])\n",
    "    return goal.reshape((puzzle_dim, puzzle_dim)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics computation\n",
    "Quality, cost and elapsed time are computed. Useful in particular for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(results_values):\n",
    "    quality_sol, cost_sol, elapsed = tuple(zip(*(results_values)))\n",
    "    avg_quality, avg_cost, avg_elapsed = map(lambda x: np.mean(np.array(x)), [quality_sol, cost_sol, elapsed])\n",
    "    return avg_quality, avg_cost, avg_elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve functions\n",
    "Used to call the solver algorithm on different instances and trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_instance(puzzle_dim: int, heuristic, exp=None) -> np.ndarray:\n",
    "    goal = set_goal(puzzle_dim)\n",
    "    content = init_state(goal, puzzle_dim, randomize_steps=1400)\n",
    "    do_action.calls = 0\n",
    "    \n",
    "    converged, path = astar(content, goal, heuristic, exp=exp)\n",
    "    \n",
    "    assert converged\n",
    "\n",
    "    return quality(path), do_action.calls\n",
    "\n",
    "\n",
    "def solve_size(puzzle_dim: int, heuristic, tries: int = TRIALS_BASE, exp=None):\n",
    "    \n",
    "    qualities, costs = [], []\n",
    "    for t in range(tries):\n",
    "        print(f\"Instance {t}\")\n",
    "        sol_quality, sol_cost = solve_instance(puzzle_dim, heuristic, exp=exp)\n",
    "        qualities.append(sol_quality)\n",
    "        costs.append(sol_cost)\n",
    "    \n",
    "    tot_quality, tot_cost = map(lambda x: np.array(x).mean(), [qualities, costs])\n",
    "    \n",
    "    return tot_quality, tot_cost, tot_quality / tot_cost\n",
    "\n",
    "\n",
    "def solve(min_puz_dim, max_puz_dim, heuristics: dict, exp: dict = None, tries: dict = None):\n",
    "    \n",
    "    names = [\"quality\", \"cost\", \"efficiency\"]\n",
    "    results = dict()\n",
    "    for puzzle_dim in range(min_puz_dim, max_puz_dim+1):\n",
    "        print(f\"Solving for size {puzzle_dim}\")\n",
    "        sol_quality, sol_cost, sol_efficiency = solve_size(puzzle_dim, heuristics[puzzle_dim], tries[puzzle_dim], exp=exp[puzzle_dim])\n",
    "        \n",
    "        results[puzzle_dim] = dict(zip(names, [sol_quality, sol_cost, sol_efficiency]))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics data structure\n",
    "Used as helper for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\"fixed\", \"step scheduling\", \"arctan scheduling\"]\n",
    "functions = [fixed_heuristic, step_scheduling_heuristic, arctan_scheduling_heuristic]\n",
    "heuristics = dict(zip(strategies, functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setup\n",
    "Used to set the values of the parameters for each problem size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEURISTICS_PER_SIZE = {\n",
    "    2: fixed_heuristic,\n",
    "    3: fixed_heuristic,\n",
    "    4: fixed_heuristic,\n",
    "    5: fixed_heuristic,\n",
    "    6: fixed_heuristic,\n",
    "    7: fixed_heuristic,\n",
    "    8: fixed_heuristic,\n",
    "    9: fixed_heuristic\n",
    "}\n",
    "EXP_PER_SIZE = {\n",
    "    puzzle_dim: 1 if puzzle_dim <= 3 else (1.8 if puzzle_dim <= 7 else 4) for puzzle_dim in range(MIN_PUZZLE_DIM, MAX_PUZZLE_DIM+1)\n",
    "}\n",
    "TRIALS_PER_SIZE = {\n",
    "    2: TRIALS_BASE,\n",
    "    3: TRIALS_BASE,\n",
    "    4: TRIALS_BASE,\n",
    "    5: TRIALS_BASE // 2,\n",
    "    6: TRIALS_BASE // 4,\n",
    "    7: TRIALS_BASE // 8,\n",
    "    8: TRIALS_BASE // 8,\n",
    "    9: TRIALS_BASE // 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output functions\n",
    "Used to print, save on file and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    for (puzzle_dim, result) in results.items():\n",
    "        print(f\"Puzzle dimension: {puzzle_dim}\")\n",
    "        avg_quality, avg_cost, avg_efficiency = map(result.get, list(result.keys()))\n",
    "        print(f\"Quality: {avg_quality:.5f}\")\n",
    "        print(f\"Cost: {avg_cost:.3f}\")\n",
    "        print(f\"Efficiency: {avg_efficiency:.3e}\")\n",
    "        print()\n",
    "\n",
    "def save_results(results: dict, filename: str):\n",
    "    file = open(filename, mode=\"w\", encoding=\"utf-8\")\n",
    "    json.dump(results, file, indent=4)\n",
    "    \n",
    "def plot_results(results):\n",
    "    puz_dimensions, qualities, costs, efficiencies = [], [], [], []\n",
    "    for (puzzle_dim, result) in results.items():\n",
    "        avg_quality, avg_cost, avg_efficiency = map(result.get, list(result.keys()))\n",
    "        \n",
    "        puz_dimensions.append(int(puzzle_dim))\n",
    "        qualities.append(avg_quality)\n",
    "        costs.append(avg_cost)\n",
    "        efficiencies.append(avg_efficiency)\n",
    "    \n",
    "    plt.figure(\"efficiency\")\n",
    "    \n",
    "    plt.semilogy(puz_dimensions, efficiencies, label=\"Efficiency\", marker=\"o\", mfc=\"red\", mec=\"black\")\n",
    "    \n",
    "    for (x, y) in zip(puz_dimensions, efficiencies):\n",
    "        plt.text(x+0.02, 1.2*y, EXP_PER_SIZE[x])\n",
    "    \n",
    "    plt.suptitle(\"Efficiency\", size=12)\n",
    "    plt.title(\"Markers are annotated with exponent used\", size=10)\n",
    "    plt.xlabel(\"Puzzle dimension\")\n",
    "    plt.ylabel(\"Efficiency\")\n",
    "    plt.grid()\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = solve(2, 3, HEURISTICS_PER_SIZE, EXP_PER_SIZE, TRIALS_PER_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(results, OUTFILE)\n",
    "print_results(results)\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solvers\n",
    "Ad-hoc solvers use as helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(name, strategy, content, goal, exp=None):\n",
    "\tstart = time()\n",
    "\n",
    "\tdo_action.calls = 0\n",
    "\tsuccess, path = astar(content, goal, strategy, exp=exp)\n",
    "\telapsed = time() - start\n",
    "\n",
    "\tquality_sol, cost_sol = quality(path), do_action.calls\n",
    "\tprint(f\"{name}, {exp}: {success}, {quality_sol}, {cost_sol}, time: {elapsed:.2f} s\")\n",
    "\t\n",
    "\treturn ((name, exp), (quality_sol, cost_sol, elapsed))\n",
    "\n",
    "\n",
    "def solve_instance(content, goal, results, heuristics=heuristics, exp_values=[2,3]):\n",
    "\tfor (name, strategy) in heuristics.items():\n",
    "\t\tif name == \"fixed\":\n",
    "\t\t\tfor exp in exp_values:\n",
    "\t\t\t\talgorithm, result = solve(name, strategy, content, goal, exp=exp)\n",
    "\t\t\t\tcurrent = results.get(algorithm, [])\n",
    "\t\t\t\tcurrent.append(result)\n",
    "\t\t\t\tresults[algorithm] = current\n",
    "\t\telse:\n",
    "\t\t\talgorithm, result = solve(name, strategy, content, goal)\n",
    "\t\t\tcurrent = results.get(algorithm, [])\n",
    "\t\t\tcurrent.append(result)\n",
    "\t\t\tresults[algorithm] = current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic modification\n",
    "Admissible heuristics are sometimes too slow at converging. The following part aims to find a non-admissible heuristic which can represent a good trade-off between optimality of the final solution and convergence time, which is related to the total cost of the problem (number of explored states)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\t\n",
    "\n",
    "TRIALS = 15\n",
    "for i in range(TRIALS):\n",
    "\tgoal = np.array([n for n in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\tcontent = init_state(goal)\n",
    "\tprint(f\"Instance {i}\")\n",
    "\tprint(content)\n",
    "\tsolve_instance(content, goal, results)\n",
    "\n",
    "for (algorithm, result) in results.items():\n",
    "    avg_results = statistics(result)\n",
    "    print(algorithm, avg_results)\n",
    "\n",
    "# RAW RESULTS\n",
    "# ('fixed', 2) (0.007514, 14753.52)\n",
    "# ('fixed', 3) (0.006289, 15408.64)\n",
    "# ('step scheduling', None) (0.009345, 53037.26)\n",
    "# ('arctan scheduling', None) (0.007299, 26842.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for randomizer step\n",
    "This experiment focuses on understanding how could the number of initial randomize steps influence the final solution, in terms of quality and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualities, costs, elapseds = [], [], []\n",
    "\n",
    "TRIALS = 15\n",
    "values = list(map(int, np.logspace(1, 7, num=TRIALS).tolist()))\n",
    "for (i, rand_steps) in enumerate(values):\n",
    "\tgoal = np.array([n for n in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\t\n",
    "\tprint(f\"{i}: {rand_steps}\")\n",
    " \n",
    "\t_TRIALS = 10\n",
    "\t_qualities, _costs, _elapseds = map(np.zeros, [_TRIALS] * 3)\n",
    "\tfor _try in tqdm(range(_TRIALS)):\n",
    "\t\tcontent = init_state(goal, randomize_steps=rand_steps)\n",
    "\t\t_, (sol_quality, sol_cost, sol_elapsed) = solve(\"fixed\", fixed_heuristic, content, goal, exp=2)\n",
    "\t\t_qualities[_try] = sol_quality\n",
    "\t\t_costs[_try] = sol_cost\n",
    "\t\t_elapseds[_try] = sol_elapsed\n",
    "\t\n",
    "\tsol_quality = _qualities.mean()\n",
    "\tsol_cost = _costs.mean()\n",
    "\tsol_elapsed = _elapseds.mean()\n",
    "\t\n",
    "\tqualities.append(sol_quality)\n",
    "\tcosts.append(sol_cost)\n",
    "\telapseds.append(sol_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"scatter\", figsize=(14,8))\n",
    "plt.scatter(costs, qualities)\n",
    "plt.title(\"Quality vs. cost scatterplot\")\n",
    "plt.xlabel(\"Cost\")\n",
    "plt.ylabel(\"Quality\")\n",
    "for (i, (c, q)) in enumerate(zip(costs, qualities)):\n",
    "    plt.annotate(f\"{int(values[i]):1d}\", (c,q))\n",
    "plt.grid(linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff = ((np.array(qualities[2:]) / np.array(costs[2:]))).tolist()\n",
    "v = sorted([(s, e) for (s, e) in zip(values[2:]], eff)])\n",
    "s = [x[0] for x in v]\n",
    "e = [x[1] for x in v]\n",
    "plt.figure(\"efficiency\", figsize=(14,8))\n",
    "plt.semilogx(s, e)\n",
    "plt.title(\"Efficiency vs. Random steps\")\n",
    "plt.xlabel(\"Random steps\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "For n > 200, the scatter points are always in the same region.\n",
    "Hence, it is expected the algorithm behave in the same way across different instances, given n greater than some constant N.\n",
    "\n",
    "To have some safety margin N >= 1000 is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained fixed exponent\n",
    "Fixed exponent is chosen, since it balances quality vs cost better than others.\n",
    "The value of the exponent is tweaked around 2, in a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "fixed_heur = dict(zip([strategies[0]], [functions[0]]))\n",
    "exp_values = np.linspace(1.5, 2.2, num=8).tolist()[::-1]      # 0.1 step, starting from fastest\n",
    "\n",
    "rand_steps_values = [1000, 1400]\n",
    "for rand_steps in rand_steps_values:\n",
    "    TRIALS = 10\n",
    "    for i in range(TRIALS):\n",
    "        goal = np.array([n for n in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "        content = init_state(goal, randomize_steps=rand_steps)\n",
    "        print(f\"Instance {i}\")\n",
    "        print(content)\n",
    "        results[rand_steps] = dict()\n",
    "        solve_instance(content, goal, results[rand_steps], heuristics=fixed_heur, exp_values=exp_values)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = dict()\n",
    "keys = [\"quality\", \"cost\", \"elapsed\"]\n",
    "\n",
    "for (rand_steps, results_rand_steps) in results.items():\n",
    "    avg_results[rand_steps] = dict()\n",
    "    for ((_, exp), result) in results_rand_steps.items():\n",
    "        avg_result = statistics(result)\n",
    "        values = list(map(float, avg_result))\n",
    "        avg_results[rand_steps][exp] = dict(zip(keys, values))\n",
    "\n",
    "avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiencies = {rand_steps: [val[\"quality\"]/val[\"cost\"] for val in avg_results_steps.values()] for (rand_steps, avg_results_steps) in avg_results.items()}\n",
    "efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = {rand_steps: [val[\"cost\"] for val in avg_results_steps.values()] for (rand_steps, avg_results_steps) in avg_results.items()}\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"cost vs. exp\", figsize=(14,8))\n",
    "colors = [\"b\", \"r\", \"orange\"]\n",
    "for ((rand_steps, cost_steps), color) in zip(costs.items(), colors):\n",
    "    plt.plot(exp_values, cost_steps, label=f\"{rand_steps}\", color=color)\n",
    "plt.legend(title=\"Rand. steps\")\n",
    "plt.title(\"Cost vs Exponent\")\n",
    "plt.xlabel(\"Exponent\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"eff vs. exp\", figsize=(14,8))\n",
    "colors = [\"b\", \"r\", \"orange\"]\n",
    "for ((rand_steps, efficiencies_steps), color) in zip(efficiencies.items(), colors):\n",
    "    plt.plot(exp_values, efficiencies_steps, label=f\"{rand_steps}\", color=color)\n",
    "plt.legend(title=\"Rand. steps\")\n",
    "plt.title(\"Efficiency vs Exponent\")\n",
    "plt.xlabel(\"Exponent\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "To avoid higher costs in larger problems, a low cost is preferred: by putting a threshold on 20'000 evaluations (which corresponds to about 4 seconds), the following setups are considered:\n",
    "- rand steps = 1400, $exp \\geq 1.7$\n",
    "- rand_steps = 1000, $exp = 1.8$.\n",
    "\n",
    "Efficiency is then considered:\n",
    "- rand_steps = 1400, better on the whole interval, in particular in 1.8\n",
    "- rand_steps = 1000 is worse on the whole interval, so it is discarded.\n",
    "\n",
    "In conclusion:\n",
    "- rand_steps = 1400, due to better general behavior\n",
    "- exp = 1.8, due to lower cost in the region\n",
    "  \n",
    "could be a good solution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
