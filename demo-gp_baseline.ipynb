{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "np.random.seed(42)\n",
    "x = np.random.uniform(-10, 10, 100).reshape(-1, 1)  # Input feature\n",
    "y = 3 * x[:, 0]**2 - 2 * x[:, 0] + 5 + np.random.normal(0, 10, 100)  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 3), (5000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = np.load('./data/problem_2.npz')\n",
    "x = problem['x'].T\n",
    "y = problem['y']\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    33.27      1.53874e+07        7      4.65104e+06      6.09778e+06      1.05m\n",
      "   1    35.39      4.79581e+06       63       4.6409e+06       6.1891e+06      1.01m\n",
      "   2    37.15      4.79825e+06      125      4.63972e+06      6.19959e+06      1.10m\n",
      "   3    34.00       4.7993e+06        3      4.67991e+06      5.83795e+06     56.11s\n",
      "   4    32.81      4.79697e+06        3      4.68725e+06      5.77188e+06     55.11s\n",
      "   5    28.86      4.79559e+06      127      4.67295e+06      5.90023e+06      1.03m\n",
      "   6    30.82       4.7954e+06       31      4.63979e+06      6.19909e+06     57.41s\n",
      "   7    30.77      4.79496e+06       91      4.68976e+06      5.74822e+06     58.72s\n",
      "   8    33.25      4.79528e+06       11      4.69361e+06      5.71466e+06     50.39s\n",
      "   9    31.22      4.79585e+06        5      4.65695e+06       6.0447e+06     42.97s\n",
      "  10    29.22      4.79449e+06      115      4.69117e+06      5.73666e+06     42.85s\n",
      "  11    30.21      4.79477e+06       19      4.69953e+06      5.66148e+06     44.99s\n",
      "  12    37.43      4.79641e+06        3      4.68705e+06      5.77373e+06     37.94s\n",
      "  13    34.99      4.79484e+06        1       4.6829e+06      5.81104e+06     35.21s\n",
      "  14    35.26       4.7958e+06       47      4.68119e+06      5.82655e+06     30.46s\n",
      "  15    34.91      4.79421e+06        5      4.68585e+06      5.78447e+06     30.47s\n",
      "  16    31.62      4.81175e+06        7      4.69353e+06      5.71536e+06     27.57s\n",
      "  17    31.68      4.79761e+06       17      4.68166e+06       5.8222e+06     26.79s\n",
      "  18    31.78      4.79438e+06       19      4.67362e+06      5.89458e+06     23.49s\n",
      "  19    28.76      4.79565e+06       65      4.68145e+06      5.82397e+06     24.02s\n",
      "  20    28.47      4.79658e+06       15       4.6868e+06      5.77595e+06     22.50s\n",
      "  21    29.05      4.79578e+06        1      4.67855e+06      5.85021e+06     19.45s\n",
      "  22    32.93       4.7959e+06       45      4.66483e+06      5.98465e+06     17.62s\n",
      "  23    37.03      4.80221e+06       89      4.68281e+06      5.38255e+06     16.30s\n",
      "  24    46.67      4.82631e+06      129      4.63025e+06      4.76876e+06     13.64s\n",
      "  25    78.70      1.54566e+07      125       4.5799e+06      5.05376e+06     14.66s\n",
      "  26   106.42      2.84703e+08       89      4.53899e+06      5.32837e+06     12.66s\n",
      "  27   116.64      1.09713e+09       79      4.49938e+06      5.36698e+06      8.18s\n",
      "  28   118.18      9.70427e+08      169      4.49599e+06      5.58076e+06      5.19s\n",
      "  29   128.22      1.16857e+09      113      4.50848e+06      5.28774e+06      0.00s\n",
      "Best formula: mul(mul(sub(add(-0.570, sub(sub(X2, X0), add(X0, 0.934))), add(mul(sub(X1, X1), add(X0, 0.934)), sub(div(mul(sub(add(sub(mul(mul(X2, X1), div(X2, 0.300)), div(X0, 0.283)), div(X2, add(X1, 0.315))), X0), mul(mul(X0, X2), div(X2, X2))), 0.557), div(X1, mul(div(mul(X1, X1), div(div(X2, 0.300), sub(X2, 0.182))), add(mul(X0, X1), add(div(mul(X1, X1), mul(X0, X1)), sub(add(div(X0, X0), 0.922), div(X2, X0))))))))), mul(X0, X1)), add(mul(X0, X1), add(div(mul(X1, X1), div(div(X2, 0.300), sub(X2, 0.182))), sub(add(mul(X0, X1), 0.922), div(X2, X0)))))\n"
     ]
    }
   ],
   "source": [
    "x_train, _, y_train, _ = train_test_split(x, y, train_size=0.1, random_state=42)\n",
    "\n",
    "# Define the symbolic regressor\n",
    "est = SymbolicRegressor(\n",
    "    population_size=2000,\n",
    "    generations=30,\n",
    "    stopping_criteria=0.01,\n",
    "    p_crossover=0.98,\n",
    "    p_subtree_mutation=0.01,\n",
    "    p_point_mutation=0.01,\n",
    "    p_hoist_mutation=0.00,\n",
    "    max_samples=0.9,\n",
    "    verbose=1,\n",
    "    parsimony_coefficient=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "est.fit(x_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = est.predict(x)\n",
    "\n",
    "# Print the resulting formula\n",
    "print(\"Best formula:\", est._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Validations Set: 2.81e+13\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and visualize\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"Mean Squared Error on Validations Set: {mse:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
