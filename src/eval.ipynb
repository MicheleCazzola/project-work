{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import s323270\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM = 7\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "function = eval(f\"s323270.f{PROBLEM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(f\"./data/problem_{PROBLEM}.npz\")\n",
    "print(f\"Evaluating problem {PROBLEM}\")\n",
    "x['x'].shape, x['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dim = x['x'].shape[0]\n",
    "dataset_size = x['x'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(range(dataset_size), test_size=TEST_SIZE, random_state=42)\n",
    "x_train, y_train = x['x'][:, train_indices], x['y'][train_indices]\n",
    "x_val, y_val = x['x'][:, val_indices], x['y'][val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (overall): {100*np.square(x['y']-function(x['x'])).sum()/len(x['y']):g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE on train and test split separately\n",
    "Note the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (train): {100*np.square(y_train-function(x_train)).sum()/len(y_train):g}\")\n",
    "print(f\"MSE (val) : {100*np.square(y_val-function(x_val)).sum()/len(y_val):g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and function predictions on single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(features, labels, function, problem, i):\n",
    "    \n",
    "    domain = np.zeros((features.shape[0], 1000))\n",
    "    domain[i] = np.linspace(features[i].min(), features[i].max(), 1000)\n",
    "    predicted = function(domain)\n",
    "    \n",
    "    # First subplot: X1 vs Y and X1 vs R\n",
    "    plt.scatter(features[i], labels, marker='o', s=2, color=\"r\", label='Actual')\n",
    "    plt.plot(domain[i], predicted, color=\"b\", label='Predicted')\n",
    "    plt.xlabel(f'X[{i}]')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f\"Problem {problem} - X{i}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x['x']\n",
    "labels = x['y']\n",
    "\n",
    "for i in range(features.shape[0]):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plot_solution(features, labels, function, PROBLEM, i)\n",
    "    path = f\"./results/problems/problem{PROBLEM}/x{i}.png\"\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D plot for 2D-domain datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features.shape[0] == 2:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    x0 = np.linspace(features[0].min(), features[0].max(), 1000)\n",
    "    x1 = np.linspace(features[1].min(), features[1].max(), 1000)\n",
    "    \n",
    "    X0, X1 = np.meshgrid(x0, x1)\n",
    "    grid = np.array([X0.ravel(), X1.ravel()])\n",
    "    \n",
    "    Y = function(grid).reshape(X0.shape)\n",
    "\n",
    "    # Assuming features is a 2-dimensional numpy array\n",
    "    ax.scatter(features[0], features[1], labels, c='r', s=1, alpha=0.5)\n",
    "    ax.plot_surface(X0, X1, Y, color='b', alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel('X[0]')\n",
    "    ax.set_ylabel('X[1]')\n",
    "    ax.set_zlabel('Y') \n",
    "    ax.set_box_aspect(aspect=None, zoom=0.96)\n",
    "    \n",
    "    plt.title(f\"Problem {PROBLEM}\")\n",
    "    \n",
    "    path = f\"./results/problems/problem{PROBLEM}/3d.png\"\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
